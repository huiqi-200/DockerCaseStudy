{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from: https://archive.ics.uci.edu/dataset/19/car+evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car data:\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "car_evaluation = fetch_ucirepo(id=19) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "car_evaluation_df = car_evaluation.data.features \n",
    "\n",
    "X = car_evaluation_df[['maint','doors','persons','lug_boot','safety']]\n",
    "X['class'] = car_evaluation.data.targets['class']\n",
    "y = car_evaluation_df[['buying']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkovič', 'published_in': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'url': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'doi': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "# metadata \n",
    "print(car_evaluation.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(car_evaluation.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom order for the categorical column\n",
    "x_categories_dict ={\n",
    "                \n",
    "                'maint': ['low', 'med', 'high', 'vhigh'],\n",
    "                'doors': ['2','3','4','5more'],\n",
    "                'persons': ['2','4','more'],\n",
    "                'lug_boot': ['small','med','big'],\n",
    "                'safety': ['low','med','high'],\n",
    "                'class': ['unacc', 'acc', 'good', 'vgood']\n",
    "}\n",
    "\n",
    "y_categories_dict = {\n",
    "    'buying': ['low', 'med', 'high', 'vhigh'],\n",
    "}\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "transformed_X = encoder.set_params(encoded_missing_value=-1).fit_transform(X)\n",
    "transformed_Y = encoder.set_params(encoded_missing_value=-1).fit_transform(y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, transformed_Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the ____ model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22832369942196531\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.19      0.12      0.15        92\n",
      "         1.0       0.21      0.18      0.19        83\n",
      "         2.0       0.19      0.31      0.24        77\n",
      "         3.0       0.32      0.31      0.31        94\n",
      "\n",
      "    accuracy                           0.23       346\n",
      "   macro avg       0.23      0.23      0.22       346\n",
      "weighted avg       0.23      0.23      0.22       346\n",
      "\n",
      "Coefficients: [[-0.0056364  -0.01396603 -0.02885368  0.02504834  0.01564097 -0.12467016]\n",
      " [-0.01888805  0.00386267  0.01140262  0.04260909 -0.00813174  0.04435731]\n",
      " [ 0.01575472  0.03163789 -0.05648301 -0.04157133 -0.0038904  -0.08304333]\n",
      " [ 0.00876973 -0.02153453  0.07393408 -0.0260861  -0.00361883  0.16335618]]\n",
      "Intercept: [ 0.19557549 -0.07904528  0.18962514 -0.30615535]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, transformed_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, print the model coefficients\n",
    "print(f'Coefficients: {model.coef_}')\n",
    "print(f'Intercept: {model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from [sklearn](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) on testing on various models  \n",
    "\n",
    "Wanted to iterate over multiple classification models to get best score\n",
    "\n",
    "\n",
    "Other references:  \n",
    "https://medium.com/@will_47810/how-to-train-a-linear-classification-model-using-scikit-learn-c8f166371b85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(4),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    SGDClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 0.1416184971098266\n",
      "classifier <class 'sklearn.svm._classes.SVC'>: 0.22254335260115607\n",
      "classifier <class 'sklearn.svm._classes.SVC'>: 0.06936416184971098\n",
      "classifier <class 'sklearn.gaussian_process._gpc.GaussianProcessClassifier'>: 0.22254335260115607\n",
      "classifier <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 0.22832369942196531\n",
      "classifier <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 0.18497109826589594\n",
      "classifier <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>: 0.2976878612716763\n",
      "classifier <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 0.3439306358381503\n",
      "classifier <class 'sklearn.naive_bayes.GaussianNB'>: 0.2861271676300578\n",
      "classifier <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>: 0.24277456647398843\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "\n",
    "    clf_pipeline = make_pipeline( clf)\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    score = clf_pipeline.score(X_test, y_test)\n",
    "\n",
    "    print(f\"classifier {type(clf)}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maint doors persons lug_boot safety  class\n",
       "0  vhigh     2       2    small    low  unacc"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best model\n",
    "\n",
    "clf = AdaBoostClassifier(algorithm=\"SAMME\", random_state=42)\n",
    "clf.fit(transformed_X, transformed_Y)\n",
    "\n",
    "# Define predictor parameters:\n",
    "x_predict_dict = {'maint': ['vhigh'], \n",
    "        'doors': [2],\n",
    "        'persons':[2],\n",
    "        'lug_boot':['small'],\n",
    "        'safety':['low'],\n",
    "        'class':['unacc']\n",
    "        }\n",
    "x_predict_df = pd.DataFrame(data=x_predict_dict)\n",
    "\n",
    "predict_transformed_X = encoder.set_params(encoded_missing_value=-1).fit_transform(x_predict_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'med'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "y_categories_dict['buying'][int(clf.predict(predict_transformed_X)[0]) - 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
